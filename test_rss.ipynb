{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ee1063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'link', 'published', 'summary'])\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "def get_rss_updates(rss_url):\n",
    "    feed = feedparser.parse(rss_url)\n",
    "    updates = []\n",
    "    for entry in feed.entries:\n",
    "        updates.append({\n",
    "            'title': entry.get('title', ''),\n",
    "            'link': entry.get('link', ''),\n",
    "            'published': entry.get('published', ''),\n",
    "            'summary': entry.get('summary', '')\n",
    "        })\n",
    "    return updates\n",
    "\n",
    "# Example usage:\n",
    "# rss_url = 'https://rss.arxiv.org/rss/cs'\n",
    "rss_url= 'https://www.science.org/action/showFeed?type=etoc&feed=rss&jc=science'\n",
    "updates = get_rss_updates(rss_url)\n",
    "print(updates[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a98c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Tuple, Dict\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"gpt-4.1\")\n",
    "TEMPERATURE = float(os.getenv(\"MODEL_TEMPERATURE\", 0.5))\n",
    "MAX_TOKENS = int(os.getenv(\"MODEL_MAX_TOKENS\", 150))\n",
    "OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\") or None\n",
    "\n",
    "_llm_kwargs = {\"model_name\": MODEL_NAME, \"temperature\": TEMPERATURE}\n",
    "if MAX_TOKENS:\n",
    "    _llm_kwargs[\"max_tokens\"] = MAX_TOKENS\n",
    "if OPENAI_API_BASE:\n",
    "    _llm_kwargs[\"openai_api_base\"] = OPENAI_API_BASE\n",
    "\n",
    "LLM = ChatOpenAI(**_llm_kwargs)\n",
    "\n",
    "\n",
    "class SummarizationResult(BaseModel):\n",
    "    summary: str = Field(..., description=\"Concise summary of the article\")\n",
    "    recipients: List[str] = Field(default_factory=list, description=\"Usernames to send the summary to\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SummarizationResult)\n",
    "\n",
    "def summarize_articles(\n",
    "    items: List[Tuple[str, str, str, str]], users: List[Dict[str, List[str]]]\n",
    ") -> List[SummarizationResult]:\n",
    "    \"\"\"\n",
    "    Summarize multiple articles (title, link, published, feed_summary) and\n",
    "    select recipients based on user interests. Returns structured results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Format user interests\n",
    "    user_info = \"\\n\".join(\n",
    "        f\"- {u['username']}: {', '.join(u['interests'])}\" for u in users\n",
    "    )\n",
    "\n",
    "    # Format articles\n",
    "    article_lines = []\n",
    "    for title, link, published, feed_summary in items:\n",
    "        article_lines.append(\n",
    "            f\"Title: {title}\\nLink: {link}\\nPublished: {published}\\nFeed Summary: {feed_summary}\\n\"\n",
    "        )\n",
    "\n",
    "    # Instructions for format\n",
    "    system_prompt = (\n",
    "        \"You are an assistant that summarizes news articles and recommends them to users by matching topics of interest.\\n\"\n",
    "    )\n",
    "\n",
    "    full_prompt = (\n",
    "        f\"Users and their interests:\\n{user_info}\\n\\n\"\n",
    "        f\"Articles to summarize:\\n{''.join(article_lines)}\"\n",
    "    )\n",
    "    llm = LLM.with_structured_output(SummarizationResult)\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=full_prompt)\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Try parsing using the parser\n",
    "    try:\n",
    "        \n",
    "        return [response.__dict__]  # Because it's a single result\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Model returned invalid structured output:\\n{response}\\n\\nError: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008dfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "summary = summarize_articles(\n",
    "    items=[\n",
    "        (\"Sample Title\", \"http://example.com/article\", \"2023-10-01\", \"This is a sample summary of the article.\"),\n",
    "    ],\n",
    "    users=[\n",
    "        {\"username\": \"user1\", \"interests\": [\"science\", \"technology\"]},\n",
    "        {\"username\": \"user2\", \"interests\": [\"health\", \"environment\"]},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e184a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/4134lvvs5wjcfkw_mzqz721jy4h4ck/T/ipykernel_78416/3905111262.py:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  summary[0].dict().get('summary', 'No summary provided')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This is a sample summary of the article.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[0].dict().get('summary', 'No summary provided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef1598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gemma-3-27b-it-qat',\n",
       " 'model': 'gemma-3-27b-it-qat',\n",
       " 'stream': False,\n",
       " 'temperature': 0.5,\n",
       " 'max_completion_tokens': 150,\n",
       " '_type': 'openai-chat'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
